{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from typing import Iterable\n",
    "from pathlib import Path\n",
    "\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH: str = \"models\"\n",
    "\n",
    "\n",
    "def save_model(model: nn.Module, name: str):\n",
    "    torch.save(model.state_dict(), f\"{MODELS_PATH}/{name}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FashionMNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# split into validation and train datasets\n",
    "train_ds = datasets.FashionMNIST(\"data\", train=True, transform=transform, download=True)\n",
    "train_ds, valid_ds = random_split(train_ds, [0.8, 0.2])\n",
    "\n",
    "test_ds = datasets.FashionMNIST(\"data\", train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            1, 6, kernel_size=5, stride=1, padding=2\n",
    "        )  # 28*28->32*32-->28*28\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the constants\n",
    "BATCH_SIZE: int = 32\n",
    "LEARNING_RATE: float = 0.01\n",
    "EPOCHS: int = 50\n",
    "MOMENTUM: float = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LeNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "early_stopper = utility.early_stopping.EarlyStopper(patience=3, min_delta=0)\n",
    "optimizer = optim.SGD(base_model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "# create the data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bubuss/miniforge3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1699449183005/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss: 0.7884, Valid Loss: 0.4886, Valid Accuracy: 0.8151\n",
      "Epoch: 1\n",
      "Train Loss: 0.4554, Valid Loss: 0.4038, Valid Accuracy: 0.8444\n",
      "Epoch: 2\n",
      "Train Loss: 0.3905, Valid Loss: 0.3699, Valid Accuracy: 0.8601\n",
      "Epoch: 3\n",
      "Train Loss: 0.3568, Valid Loss: 0.3417, Valid Accuracy: 0.8772\n",
      "Epoch: 4\n",
      "Train Loss: 0.3247, Valid Loss: 0.3019, Valid Accuracy: 0.8880\n",
      "Epoch: 5\n",
      "Train Loss: 0.3057, Valid Loss: 0.2951, Valid Accuracy: 0.8907\n",
      "Epoch: 6\n",
      "Train Loss: 0.2894, Valid Loss: 0.2982, Valid Accuracy: 0.8910\n",
      "Epoch: 7\n",
      "Train Loss: 0.2729, Valid Loss: 0.2820, Valid Accuracy: 0.8919\n",
      "Epoch: 8\n",
      "Train Loss: 0.2611, Valid Loss: 0.2865, Valid Accuracy: 0.8935\n",
      "Epoch: 9\n",
      "Train Loss: 0.2524, Valid Loss: 0.2865, Valid Accuracy: 0.8964\n",
      "Epoch: 10\n",
      "Train Loss: 0.2433, Valid Loss: 0.2831, Valid Accuracy: 0.8967\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss = utility.training.train_epoch(\n",
    "        module=base_model,\n",
    "        train_dl=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        loss_function=cross_entropy,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    valid_loss, valid_accuracy = utility.training.validate(\n",
    "        module=base_model,\n",
    "        valid_dl=validation_loader,\n",
    "        loss_function=cross_entropy,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch:}\\nTrain Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "    if early_stopper.early_stop(valid_loss):\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.302720 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, accuracy = utility.training.test(\n",
    "    base_model, test_dl=test_loader, loss_function=cross_entropy, device=device\n",
    ")\n",
    "print(f\"Test Error: \\n Accuracy: {accuracy:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(base_model, f\"{type(base_model).__name__}_fmnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters_to_prune(model: nn.Module) -> list[nn.Parameter]:\n",
    "    return [\n",
    "        (module, \"weight\")\n",
    "        for module in model.modules()\n",
    "        if isinstance(module, nn.Conv2d | nn.Linear)\n",
    "    ]\n",
    "\n",
    "\n",
    "def calculate_total_sparsity(\n",
    "    module: nn.Module, parameters_to_prune: Iterable[tuple[nn.Module, str]]\n",
    ") -> float:\n",
    "    total_weights = 0\n",
    "    total_zero_weights = 0\n",
    "\n",
    "    pruned_parameters: set[tuple[nn.Module, str]] = set(parameters_to_prune)\n",
    "\n",
    "    for _, module in module.named_children():\n",
    "        for param_name, param in module.named_parameters():\n",
    "            if (module, param_name) not in pruned_parameters:\n",
    "                continue\n",
    "\n",
    "            if \"weight\" in param_name:\n",
    "                total_weights += float(param.nelement())\n",
    "                total_zero_weights += float(torch.sum(param == 0))\n",
    "\n",
    "    sparsity = 100.0 * total_zero_weights / total_weights\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One shot pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRUNING_VALUES = [0.2, 0.4, 0.6, 0.8, 0.9, 0.95]\n",
    "PRUNING_METHODS = {\n",
    "    \"RandomUnstructured\": prune.RandomUnstructured,\n",
    "    \"L1Unstructured\": prune.L1Unstructured,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_parameters_amount(modules: Iterable[tuple[nn.Module, str]]) -> int:\n",
    "    \"\"\"Calculate the total amount of parameters in a list of modules.\n",
    "\n",
    "    Args:\n",
    "        modules (Iterable[tuple[nn.Module, str]]): List of modules and the parameter names.\n",
    "\n",
    "    Returns:\n",
    "        int: The total amount of parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    total_parameters = 0\n",
    "    for module, parameter in modules:\n",
    "        for param_name, param in module.named_parameters():\n",
    "            if param_name == parameter:\n",
    "                total_parameters += param.nelement()\n",
    "\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning rate: 0.2, method: RandomUnstructured\n",
      "After pruning:\n",
      "Valid Loss: 0.5672, Valid Accuracy: 0.7842\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.2702, Valid Accuracy: 0.8997\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.2985, Valid Accuracy: 0.8941\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2777, Valid Accuracy: 0.8969\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2550, Valid Accuracy: 0.9051\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2823, Valid Accuracy: 0.8952\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.2671, Valid Accuracy: 0.9010\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.2665, Valid Accuracy: 0.9049\n",
      "Early stopping\n",
      "Pruning rate: 0.2, method: L1Unstructured\n",
      "After pruning:\n",
      "Valid Loss: 0.2829, Valid Accuracy: 0.8968\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.2832, Valid Accuracy: 0.8974\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.2741, Valid Accuracy: 0.9022\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2821, Valid Accuracy: 0.8997\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2651, Valid Accuracy: 0.9040\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2714, Valid Accuracy: 0.9057\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.2774, Valid Accuracy: 0.9037\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.2645, Valid Accuracy: 0.9097\n",
      "Epoch: 7\n",
      "Train Loss: 0.2433, Valid Loss: 0.2747, Valid Accuracy: 0.9043\n",
      "Epoch: 8\n",
      "Train Loss: 0.2433, Valid Loss: 0.2784, Valid Accuracy: 0.9058\n",
      "Epoch: 9\n",
      "Train Loss: 0.2433, Valid Loss: 0.2815, Valid Accuracy: 0.9046\n",
      "Early stopping\n",
      "Pruning rate: 0.4, method: RandomUnstructured\n",
      "After pruning:\n",
      "Valid Loss: 1.6749, Valid Accuracy: 0.3979\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.2930, Valid Accuracy: 0.8907\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.2749, Valid Accuracy: 0.8987\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2770, Valid Accuracy: 0.8999\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2699, Valid Accuracy: 0.9015\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2796, Valid Accuracy: 0.8968\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.2690, Valid Accuracy: 0.9006\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.2659, Valid Accuracy: 0.9041\n",
      "Epoch: 7\n",
      "Train Loss: 0.2433, Valid Loss: 0.2605, Valid Accuracy: 0.9048\n",
      "Epoch: 8\n",
      "Train Loss: 0.2433, Valid Loss: 0.2615, Valid Accuracy: 0.9037\n",
      "Epoch: 9\n",
      "Train Loss: 0.2433, Valid Loss: 0.2984, Valid Accuracy: 0.8939\n",
      "Epoch: 10\n",
      "Train Loss: 0.2433, Valid Loss: 0.2601, Valid Accuracy: 0.9091\n",
      "Epoch: 11\n",
      "Train Loss: 0.2433, Valid Loss: 0.2832, Valid Accuracy: 0.9011\n",
      "Epoch: 12\n",
      "Train Loss: 0.2433, Valid Loss: 0.2718, Valid Accuracy: 0.9054\n",
      "Epoch: 13\n",
      "Train Loss: 0.2433, Valid Loss: 0.2711, Valid Accuracy: 0.9095\n",
      "Early stopping\n",
      "Pruning rate: 0.4, method: L1Unstructured\n",
      "After pruning:\n",
      "Valid Loss: 0.2815, Valid Accuracy: 0.8974\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.2676, Valid Accuracy: 0.9017\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.2687, Valid Accuracy: 0.9046\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2652, Valid Accuracy: 0.9055\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2749, Valid Accuracy: 0.9025\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2755, Valid Accuracy: 0.9015\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.2732, Valid Accuracy: 0.9016\n",
      "Early stopping\n",
      "Pruning rate: 0.6, method: RandomUnstructured\n",
      "After pruning:\n",
      "Valid Loss: 2.3583, Valid Accuracy: 0.1062\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.3432, Valid Accuracy: 0.8737\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.3231, Valid Accuracy: 0.8798\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2993, Valid Accuracy: 0.8914\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2961, Valid Accuracy: 0.8911\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2926, Valid Accuracy: 0.8927\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.2855, Valid Accuracy: 0.8963\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.2765, Valid Accuracy: 0.8990\n",
      "Epoch: 7\n",
      "Train Loss: 0.2433, Valid Loss: 0.2741, Valid Accuracy: 0.9005\n",
      "Epoch: 8\n",
      "Train Loss: 0.2433, Valid Loss: 0.2596, Valid Accuracy: 0.9033\n",
      "Epoch: 9\n",
      "Train Loss: 0.2433, Valid Loss: 0.2912, Valid Accuracy: 0.8951\n",
      "Epoch: 10\n",
      "Train Loss: 0.2433, Valid Loss: 0.2767, Valid Accuracy: 0.9011\n",
      "Epoch: 11\n",
      "Train Loss: 0.2433, Valid Loss: 0.2632, Valid Accuracy: 0.9067\n",
      "Early stopping\n",
      "Pruning rate: 0.6, method: L1Unstructured\n",
      "After pruning:\n",
      "Valid Loss: 0.2803, Valid Accuracy: 0.8987\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.2753, Valid Accuracy: 0.9016\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.2595, Valid Accuracy: 0.9071\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2701, Valid Accuracy: 0.9045\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2665, Valid Accuracy: 0.9072\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2785, Valid Accuracy: 0.9054\n",
      "Early stopping\n",
      "Pruning rate: 0.8, method: RandomUnstructured\n",
      "After pruning:\n",
      "Valid Loss: 2.4000, Valid Accuracy: 0.1440\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.4880, Valid Accuracy: 0.8191\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.4089, Valid Accuracy: 0.8497\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.3844, Valid Accuracy: 0.8560\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.3531, Valid Accuracy: 0.8702\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.3772, Valid Accuracy: 0.8608\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.3957, Valid Accuracy: 0.8557\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.3361, Valid Accuracy: 0.8726\n",
      "Epoch: 7\n",
      "Train Loss: 0.2433, Valid Loss: 0.3248, Valid Accuracy: 0.8783\n",
      "Epoch: 8\n",
      "Train Loss: 0.2433, Valid Loss: 0.3213, Valid Accuracy: 0.8826\n",
      "Epoch: 9\n",
      "Train Loss: 0.2433, Valid Loss: 0.3245, Valid Accuracy: 0.8781\n",
      "Epoch: 10\n",
      "Train Loss: 0.2433, Valid Loss: 0.3077, Valid Accuracy: 0.8892\n",
      "Epoch: 11\n",
      "Train Loss: 0.2433, Valid Loss: 0.3291, Valid Accuracy: 0.8721\n",
      "Epoch: 12\n",
      "Train Loss: 0.2433, Valid Loss: 0.3015, Valid Accuracy: 0.8884\n",
      "Epoch: 13\n",
      "Train Loss: 0.2433, Valid Loss: 0.3023, Valid Accuracy: 0.8870\n",
      "Epoch: 14\n",
      "Train Loss: 0.2433, Valid Loss: 0.3070, Valid Accuracy: 0.8863\n",
      "Epoch: 15\n",
      "Train Loss: 0.2433, Valid Loss: 0.2971, Valid Accuracy: 0.8917\n",
      "Epoch: 16\n",
      "Train Loss: 0.2433, Valid Loss: 0.2899, Valid Accuracy: 0.8925\n",
      "Epoch: 17\n",
      "Train Loss: 0.2433, Valid Loss: 0.3176, Valid Accuracy: 0.8846\n",
      "Epoch: 18\n",
      "Train Loss: 0.2433, Valid Loss: 0.3109, Valid Accuracy: 0.8877\n",
      "Epoch: 19\n",
      "Train Loss: 0.2433, Valid Loss: 0.3072, Valid Accuracy: 0.8871\n",
      "Early stopping\n",
      "Pruning rate: 0.8, method: L1Unstructured\n",
      "After pruning:\n",
      "Valid Loss: 0.3025, Valid Accuracy: 0.8886\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.2736, Valid Accuracy: 0.9003\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.2657, Valid Accuracy: 0.9032\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2801, Valid Accuracy: 0.9001\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2629, Valid Accuracy: 0.9066\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2650, Valid Accuracy: 0.9053\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.2792, Valid Accuracy: 0.9042\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.2784, Valid Accuracy: 0.8995\n",
      "Early stopping\n",
      "Pruning rate: 0.9, method: RandomUnstructured\n",
      "After pruning:\n",
      "Valid Loss: 2.3626, Valid Accuracy: 0.1025\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.6136, Valid Accuracy: 0.7730\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.5156, Valid Accuracy: 0.8058\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.4502, Valid Accuracy: 0.8367\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.4309, Valid Accuracy: 0.8439\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.4018, Valid Accuracy: 0.8568\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.3871, Valid Accuracy: 0.8631\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.3822, Valid Accuracy: 0.8656\n",
      "Epoch: 7\n",
      "Train Loss: 0.2433, Valid Loss: 0.3759, Valid Accuracy: 0.8640\n",
      "Epoch: 8\n",
      "Train Loss: 0.2433, Valid Loss: 0.3669, Valid Accuracy: 0.8717\n",
      "Epoch: 9\n",
      "Train Loss: 0.2433, Valid Loss: 0.3681, Valid Accuracy: 0.8676\n",
      "Epoch: 10\n",
      "Train Loss: 0.2433, Valid Loss: 0.3746, Valid Accuracy: 0.8692\n",
      "Epoch: 11\n",
      "Train Loss: 0.2433, Valid Loss: 0.3351, Valid Accuracy: 0.8815\n",
      "Epoch: 12\n",
      "Train Loss: 0.2433, Valid Loss: 0.3407, Valid Accuracy: 0.8783\n",
      "Epoch: 13\n",
      "Train Loss: 0.2433, Valid Loss: 0.3317, Valid Accuracy: 0.8796\n",
      "Epoch: 14\n",
      "Train Loss: 0.2433, Valid Loss: 0.3780, Valid Accuracy: 0.8636\n",
      "Epoch: 15\n",
      "Train Loss: 0.2433, Valid Loss: 0.3279, Valid Accuracy: 0.8821\n",
      "Epoch: 16\n",
      "Train Loss: 0.2433, Valid Loss: 0.3248, Valid Accuracy: 0.8855\n",
      "Epoch: 17\n",
      "Train Loss: 0.2433, Valid Loss: 0.3416, Valid Accuracy: 0.8762\n",
      "Epoch: 18\n",
      "Train Loss: 0.2433, Valid Loss: 0.3215, Valid Accuracy: 0.8842\n",
      "Epoch: 19\n",
      "Train Loss: 0.2433, Valid Loss: 0.3226, Valid Accuracy: 0.8836\n",
      "Epoch: 20\n",
      "Train Loss: 0.2433, Valid Loss: 0.3244, Valid Accuracy: 0.8823\n",
      "Epoch: 21\n",
      "Train Loss: 0.2433, Valid Loss: 0.3133, Valid Accuracy: 0.8877\n",
      "Epoch: 22\n",
      "Train Loss: 0.2433, Valid Loss: 0.3138, Valid Accuracy: 0.8888\n",
      "Epoch: 23\n",
      "Train Loss: 0.2433, Valid Loss: 0.3209, Valid Accuracy: 0.8868\n",
      "Epoch: 24\n",
      "Train Loss: 0.2433, Valid Loss: 0.3389, Valid Accuracy: 0.8798\n",
      "Early stopping\n",
      "Pruning rate: 0.9, method: L1Unstructured\n",
      "After pruning:\n",
      "Valid Loss: 0.6619, Valid Accuracy: 0.7759\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.2783, Valid Accuracy: 0.8999\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.2725, Valid Accuracy: 0.9016\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2685, Valid Accuracy: 0.9021\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2700, Valid Accuracy: 0.9028\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2730, Valid Accuracy: 0.9013\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.2633, Valid Accuracy: 0.9038\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.2715, Valid Accuracy: 0.9028\n",
      "Epoch: 7\n",
      "Train Loss: 0.2433, Valid Loss: 0.2677, Valid Accuracy: 0.9027\n",
      "Epoch: 8\n",
      "Train Loss: 0.2433, Valid Loss: 0.2820, Valid Accuracy: 0.8955\n",
      "Early stopping\n",
      "Pruning rate: 0.95, method: RandomUnstructured\n",
      "After pruning:\n",
      "Valid Loss: 2.3562, Valid Accuracy: 0.1001\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 2.0599, Valid Accuracy: 0.3284\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.8124, Valid Accuracy: 0.6799\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.6885, Valid Accuracy: 0.7436\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.6500, Valid Accuracy: 0.7364\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.6364, Valid Accuracy: 0.7648\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.6150, Valid Accuracy: 0.7466\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.5906, Valid Accuracy: 0.7493\n",
      "Epoch: 7\n",
      "Train Loss: 0.2433, Valid Loss: 0.5795, Valid Accuracy: 0.7752\n",
      "Epoch: 8\n",
      "Train Loss: 0.2433, Valid Loss: 0.5870, Valid Accuracy: 0.7490\n",
      "Epoch: 9\n",
      "Train Loss: 0.2433, Valid Loss: 0.5647, Valid Accuracy: 0.7850\n",
      "Epoch: 10\n",
      "Train Loss: 0.2433, Valid Loss: 0.5535, Valid Accuracy: 0.7634\n",
      "Epoch: 11\n",
      "Train Loss: 0.2433, Valid Loss: 0.5602, Valid Accuracy: 0.7595\n",
      "Epoch: 12\n",
      "Train Loss: 0.2433, Valid Loss: 0.5542, Valid Accuracy: 0.7857\n",
      "Epoch: 13\n",
      "Train Loss: 0.2433, Valid Loss: 0.5412, Valid Accuracy: 0.7679\n",
      "Epoch: 14\n",
      "Train Loss: 0.2433, Valid Loss: 0.5632, Valid Accuracy: 0.7860\n",
      "Epoch: 15\n",
      "Train Loss: 0.2433, Valid Loss: 0.5292, Valid Accuracy: 0.7929\n",
      "Epoch: 16\n",
      "Train Loss: 0.2433, Valid Loss: 0.5256, Valid Accuracy: 0.7978\n",
      "Epoch: 17\n",
      "Train Loss: 0.2433, Valid Loss: 0.5209, Valid Accuracy: 0.8013\n",
      "Epoch: 18\n",
      "Train Loss: 0.2433, Valid Loss: 0.5224, Valid Accuracy: 0.7773\n",
      "Epoch: 19\n",
      "Train Loss: 0.2433, Valid Loss: 0.5070, Valid Accuracy: 0.7813\n",
      "Epoch: 20\n",
      "Train Loss: 0.2433, Valid Loss: 0.5131, Valid Accuracy: 0.7979\n",
      "Epoch: 21\n",
      "Train Loss: 0.2433, Valid Loss: 0.5065, Valid Accuracy: 0.7819\n",
      "Epoch: 22\n",
      "Train Loss: 0.2433, Valid Loss: 0.5534, Valid Accuracy: 0.7641\n",
      "Epoch: 23\n",
      "Train Loss: 0.2433, Valid Loss: 0.4984, Valid Accuracy: 0.8037\n",
      "Epoch: 24\n",
      "Train Loss: 0.2433, Valid Loss: 0.5055, Valid Accuracy: 0.7986\n",
      "Epoch: 25\n",
      "Train Loss: 0.2433, Valid Loss: 0.4994, Valid Accuracy: 0.7816\n",
      "Epoch: 26\n",
      "Train Loss: 0.2433, Valid Loss: 0.4971, Valid Accuracy: 0.8081\n",
      "Epoch: 27\n",
      "Train Loss: 0.2433, Valid Loss: 0.4916, Valid Accuracy: 0.8009\n",
      "Epoch: 28\n",
      "Train Loss: 0.2433, Valid Loss: 0.5063, Valid Accuracy: 0.7834\n",
      "Epoch: 29\n",
      "Train Loss: 0.2433, Valid Loss: 0.4954, Valid Accuracy: 0.8042\n",
      "Epoch: 30\n",
      "Train Loss: 0.2433, Valid Loss: 0.4927, Valid Accuracy: 0.7885\n",
      "Early stopping\n",
      "Pruning rate: 0.95, method: L1Unstructured\n",
      "After pruning:\n",
      "Valid Loss: 1.5574, Valid Accuracy: 0.5098\n",
      "Retraining the model\n",
      "Epoch: 0\n",
      "Train Loss: 0.2433, Valid Loss: 0.3008, Valid Accuracy: 0.8914\n",
      "Epoch: 1\n",
      "Train Loss: 0.2433, Valid Loss: 0.2880, Valid Accuracy: 0.8954\n",
      "Epoch: 2\n",
      "Train Loss: 0.2433, Valid Loss: 0.2914, Valid Accuracy: 0.8939\n",
      "Epoch: 3\n",
      "Train Loss: 0.2433, Valid Loss: 0.2793, Valid Accuracy: 0.8992\n",
      "Epoch: 4\n",
      "Train Loss: 0.2433, Valid Loss: 0.2726, Valid Accuracy: 0.8999\n",
      "Epoch: 5\n",
      "Train Loss: 0.2433, Valid Loss: 0.2806, Valid Accuracy: 0.8967\n",
      "Epoch: 6\n",
      "Train Loss: 0.2433, Valid Loss: 0.2767, Valid Accuracy: 0.9002\n",
      "Epoch: 7\n",
      "Train Loss: 0.2433, Valid Loss: 0.2865, Valid Accuracy: 0.8942\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for pruning_rate in PRUNING_VALUES:\n",
    "    pruning_value = int(\n",
    "        calculate_parameters_amount(get_parameters_to_prune(base_model)) * pruning_rate\n",
    "    )\n",
    "\n",
    "    for method_name, method in PRUNING_METHODS.items():\n",
    "        # load the model\n",
    "        temp_model = LeNet().to(device)\n",
    "        temp_model.load_state_dict(torch.load(\"models/LeNet_fmnist.pth\"))\n",
    "        model_parameters = get_parameters_to_prune(temp_model)\n",
    "\n",
    "        optimizer = optim.SGD(\n",
    "            temp_model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM\n",
    "        )\n",
    "        early_stopper = utility.early_stopping.EarlyStopper(patience=3, min_delta=0)\n",
    "\n",
    "        # prune the model\n",
    "        prune.global_unstructured(\n",
    "            parameters=model_parameters,\n",
    "            pruning_method=method,\n",
    "            amount=pruning_value,\n",
    "        )\n",
    "\n",
    "        print(f\"Pruning rate: {pruning_rate}, method: {method_name}\")\n",
    "\n",
    "        valid_loss, valid_accuracy = utility.training.validate(\n",
    "            module=temp_model,\n",
    "            valid_dl=validation_loader,\n",
    "            loss_function=cross_entropy,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"After pruning:\\nValid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\"\n",
    "        )\n",
    "\n",
    "        # retrain the model\n",
    "        print(\"Retraining the model\")\n",
    "        for epoch in range(EPOCHS):\n",
    "            utility.training.train_epoch(\n",
    "                module=temp_model,\n",
    "                train_dl=train_loader,\n",
    "                optimizer=optimizer,\n",
    "                loss_function=cross_entropy,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            valid_loss, valid_accuracy = utility.training.validate(\n",
    "                module=temp_model,\n",
    "                valid_dl=validation_loader,\n",
    "                loss_function=cross_entropy,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"Epoch: {epoch:}\\nTrain Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\"\n",
    "            )\n",
    "\n",
    "            if early_stopper.early_stop(valid_loss):\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        for module, name in model_parameters:\n",
    "            prune.remove(module, name)\n",
    "\n",
    "        torch.save(\n",
    "            temp_model.state_dict(),\n",
    "            f\"models/{type(temp_model).__name__}_pruned_{pruning_rate}_{method_name}.pth\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Iterative pruning using RandomUnstructured for 20 iterations with amount 614\n",
      "--------------------\n",
      "Iteration #1:\t validation loss: 0.2971\t validation accuracy: 0.8908\n",
      "Iteration #2:\t validation loss: 0.4532\t validation accuracy: 0.8253\n",
      "Iteration #3:\t validation loss: 0.3920\t validation accuracy: 0.8545\n",
      "Iteration #4:\t validation loss: 0.4299\t validation accuracy: 0.8335\n",
      "Iteration #5:\t validation loss: 0.4612\t validation accuracy: 0.8205\n",
      "Iteration #6:\t validation loss: 0.4395\t validation accuracy: 0.8308\n",
      "Iteration #7:\t validation loss: 0.4811\t validation accuracy: 0.8157\n",
      "Iteration #8:\t validation loss: 0.4731\t validation accuracy: 0.8187\n",
      "Iteration #9:\t validation loss: 0.4953\t validation accuracy: 0.8127\n",
      "Iteration #10:\t validation loss: 0.5172\t validation accuracy: 0.8096\n",
      "Iteration #11:\t validation loss: 0.5368\t validation accuracy: 0.8055\n",
      "Iteration #12:\t validation loss: 0.5637\t validation accuracy: 0.7971\n",
      "Iteration #13:\t validation loss: 0.5623\t validation accuracy: 0.7891\n",
      "Iteration #14:\t validation loss: 0.6522\t validation accuracy: 0.7696\n",
      "Iteration #15:\t validation loss: 0.8866\t validation accuracy: 0.6378\n",
      "Iteration #16:\t validation loss: 0.8762\t validation accuracy: 0.6414\n",
      "Iteration #17:\t validation loss: 0.9326\t validation accuracy: 0.6236\n",
      "Iteration #18:\t validation loss: 0.8529\t validation accuracy: 0.6657\n",
      "Iteration #19:\t validation loss: 0.8515\t validation accuracy: 0.6787\n",
      "Iteration #20:\t validation loss: 0.8781\t validation accuracy: 0.6710\n",
      "--------------------\n",
      "Iterative pruning using L1Unstructured for 20 iterations with amount 614\n",
      "--------------------\n",
      "Iteration #1:\t validation loss: 0.2831\t validation accuracy: 0.8967\n",
      "Iteration #2:\t validation loss: 0.2831\t validation accuracy: 0.8967\n",
      "Iteration #3:\t validation loss: 0.2830\t validation accuracy: 0.8967\n",
      "Iteration #4:\t validation loss: 0.2831\t validation accuracy: 0.8967\n",
      "Iteration #5:\t validation loss: 0.2832\t validation accuracy: 0.8967\n",
      "Iteration #6:\t validation loss: 0.2832\t validation accuracy: 0.8968\n",
      "Iteration #7:\t validation loss: 0.2832\t validation accuracy: 0.8967\n",
      "Iteration #8:\t validation loss: 0.2831\t validation accuracy: 0.8970\n",
      "Iteration #9:\t validation loss: 0.2833\t validation accuracy: 0.8971\n",
      "Iteration #10:\t validation loss: 0.2832\t validation accuracy: 0.8971\n",
      "Iteration #11:\t validation loss: 0.2830\t validation accuracy: 0.8972\n",
      "Iteration #12:\t validation loss: 0.2829\t validation accuracy: 0.8968\n",
      "Iteration #13:\t validation loss: 0.2830\t validation accuracy: 0.8971\n",
      "Iteration #14:\t validation loss: 0.2830\t validation accuracy: 0.8967\n",
      "Iteration #15:\t validation loss: 0.2831\t validation accuracy: 0.8969\n",
      "Iteration #16:\t validation loss: 0.2829\t validation accuracy: 0.8971\n",
      "Iteration #17:\t validation loss: 0.2826\t validation accuracy: 0.8972\n",
      "Iteration #18:\t validation loss: 0.2826\t validation accuracy: 0.8970\n",
      "Iteration #19:\t validation loss: 0.2828\t validation accuracy: 0.8972\n",
      "Iteration #20:\t validation loss: 0.2829\t validation accuracy: 0.8967\n"
     ]
    }
   ],
   "source": [
    "RANGE: int = 20\n",
    "ITER_PRUNING_RATE: float = 0.01\n",
    "\n",
    "pruning_value = int(\n",
    "    calculate_parameters_amount(get_parameters_to_prune(base_model)) * ITER_PRUNING_RATE\n",
    ")\n",
    "\n",
    "for method_name, method in PRUNING_METHODS.items():\n",
    "    print(\n",
    "        \"-\" * 20,\n",
    "        f\"Iterative pruning using {method_name} for {RANGE} iterations with amount {pruning_value}\",\n",
    "        \"-\" * 20,\n",
    "        sep=\"\\n\",\n",
    "    )\n",
    "\n",
    "    iterative_model = LeNet().to(device)\n",
    "    iterative_model.load_state_dict(torch.load(\"models/LeNet_fmnist.pth\"))\n",
    "\n",
    "    iterative_model_parameters = get_parameters_to_prune(iterative_model)\n",
    "    optimizer = optim.SGD(temp_model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "    for iteration in range(RANGE):\n",
    "        prune.global_unstructured(\n",
    "            parameters=iterative_model_parameters,\n",
    "            pruning_method=method,\n",
    "            amount=pruning_value,\n",
    "        )\n",
    "\n",
    "        train_loss = utility.training.train_epoch(\n",
    "            module=iterative_model,\n",
    "            train_dl=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            loss_function=cross_entropy,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        val_loss, val_accuracy = utility.training.validate(\n",
    "            module=iterative_model,\n",
    "            valid_dl=validation_loader,\n",
    "            loss_function=cross_entropy,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Iteration #{iteration + 1}:\\t validation loss: {val_loss:.4f}\\t validation accuracy: {val_accuracy:.4f}\"\n",
    "        )\n",
    "\n",
    "    for module, name in iterative_model_parameters:\n",
    "        prune.remove(module, name)\n",
    "\n",
    "    save_model(\n",
    "        iterative_model,\n",
    "        f\"{type(iterative_model).__name__}_iterative_pruned_0.{RANGE}_{method_name}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LeNet_pruned_0.2_L1Unstructured\n",
      "Loaded LeNet_pruned_0.8_RandomUnstructured\n",
      "Loaded LeNet_pruned_0.2_RandomUnstructured\n",
      "Loaded LeNet_iterative_pruned_0.20_RandomUnstructured\n",
      "Loaded LeNet_fmnist\n",
      "Loaded LeNet_pruned_0.8_L1Unstructured\n",
      "Loaded LeNet_pruned_0.4_RandomUnstructured\n",
      "Loaded LeNet_pruned_0.9_RandomUnstructured\n",
      "Loaded LeNet_iterative_pruned_0.20_L1Unstructured\n",
      "Loaded LeNet_pruned_0.95_L1Unstructured\n",
      "Loaded LeNet_pruned_0.4_L1Unstructured\n",
      "Loaded LeNet_pruned_0.6_L1Unstructured\n",
      "Loaded LeNet_pruned_0.9_L1Unstructured\n",
      "Loaded LeNet_pruned_0.95_RandomUnstructured\n",
      "Loaded LeNet_pruned_0.6_RandomUnstructured\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for file in Path(\"models\").glob(\"*.pth\"):\n",
    "    model = LeNet().to(device)\n",
    "    temp = torch.load(file)\n",
    "    model.load_state_dict(temp)\n",
    "    print(f\"Loaded {file.stem}\")\n",
    "    models.append((file.stem, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name, model in sorted(models, key=lambda x: x[0]):\n",
    "    test_loss, accuracy = utility.training.test(\n",
    "        model=model, test_dl=test_loader, loss_function=cross_entropy, device=device\n",
    "    )\n",
    "    results.append((name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LeNet_fmnist                                       accuracy: 88.95%\n",
      "Model LeNet_iterative_pruned_0.20_L1Unstructured         accuracy: 88.98%\n",
      "Model LeNet_iterative_pruned_0.20_RandomUnstructured     accuracy: 65.58%\n",
      "Model LeNet_pruned_0.2_L1Unstructured                    accuracy: 90.04%\n",
      "Model LeNet_pruned_0.2_RandomUnstructured                accuracy: 89.98%\n",
      "Model LeNet_pruned_0.4_L1Unstructured                    accuracy: 89.90%\n",
      "Model LeNet_pruned_0.4_RandomUnstructured                accuracy: 90.04%\n",
      "Model LeNet_pruned_0.6_L1Unstructured                    accuracy: 89.79%\n",
      "Model LeNet_pruned_0.6_RandomUnstructured                accuracy: 89.64%\n",
      "Model LeNet_pruned_0.8_L1Unstructured                    accuracy: 89.15%\n",
      "Model LeNet_pruned_0.8_RandomUnstructured                accuracy: 87.65%\n",
      "Model LeNet_pruned_0.95_L1Unstructured                   accuracy: 88.74%\n",
      "Model LeNet_pruned_0.95_RandomUnstructured               accuracy: 77.63%\n",
      "Model LeNet_pruned_0.9_L1Unstructured                    accuracy: 88.74%\n",
      "Model LeNet_pruned_0.9_RandomUnstructured                accuracy: 86.56%\n"
     ]
    }
   ],
   "source": [
    "for name, accuracy in results:\n",
    "    print(f\"Model {name:50s} accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the model sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sparsity for LeNet_pruned_0.2_L1Unstructured\n",
      "Total sparsity: 80.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.8_RandomUnstructured\n",
      "Total sparsity: 20.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.2_RandomUnstructured\n",
      "Total sparsity: 80.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_iterative_pruned_0.20_RandomUnstructured\n",
      "Total sparsity: 80.02%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_fmnist\n",
      "Total sparsity: 100.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.8_L1Unstructured\n",
      "Total sparsity: 20.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.4_RandomUnstructured\n",
      "Total sparsity: 60.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.9_RandomUnstructured\n",
      "Total sparsity: 10.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_iterative_pruned_0.20_L1Unstructured\n",
      "Total sparsity: 80.02%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.95_L1Unstructured\n",
      "Total sparsity: 5.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.4_L1Unstructured\n",
      "Total sparsity: 60.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.6_L1Unstructured\n",
      "Total sparsity: 40.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.9_L1Unstructured\n",
      "Total sparsity: 10.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.95_RandomUnstructured\n",
      "Total sparsity: 5.00%\n",
      "--------------------\n",
      "Calculating sparsity for LeNet_pruned_0.6_RandomUnstructured\n",
      "Total sparsity: 40.00%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    print(f\"Calculating sparsity for {name}\")\n",
    "    print(\n",
    "        f\"Total sparsity: {100 - calculate_total_sparsity(model, get_parameters_to_prune(model)):.2f}%\"\n",
    "    )\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-pruning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
